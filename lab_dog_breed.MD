# Dog Breed Identification

## Import libraries
```python
import os
import cv2
import numpy as np 
import pandas as pd 
import seaborn as sns
import matplotlib.pyplot as plt 
import sklearn
import tensorflow as tf
from sklearn.model_selection import train_test_split
from subprocess import check_output
from keras.models import Sequential
from keras.layers import Dense, Dropout 
from keras.layers import Convolution2D 
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from tqdm import tqdm
```

## Pre-process data
```python
lables = pd.read_csv('/kaggle/input/dpl-project-1-dog-breed-identification/labels.csv')
breed_count = lables['breed'].value_counts()
targets = pd.Series(lables['breed'])
one_hot = pd.get_dummies(targets, sparse = True)
one_hot_labels = np.asarray(one_hot)
img_rows= 32
img_cols= 32
num_channel= 1 # Use grayscale image
x_feature = []
y_feature = []
i = 0 # initialization
for f, img in tqdm(lables.values): # ID in `labels.csv` should help you loop through `train` folder
    train_img = cv2.imread('/kaggle/input/dpl-project-1-dog-breed-identification/train/{}.jpg'.format(f),0)
    label = one_hot_labels[i]
    train_img_resize = cv2.resize(train_img, (img_rows, img_cols)) 
    x_feature.append(train_img_resize)
    y_feature.append(label)
    i += 1
x_train_data = np.array(x_feature, np.float32) / 255. # for normalization
x_train_data = np.expand_dims(x_train_data, axis = 3)
y_train_data = np.array(y_feature, np.uint8)
x_train, x_val, y_train, y_val = train_test_split(x_train_data, y_train_data, test_size=0.2, random_state=2)
submission = pd.read_csv('/kaggle/input/dpl-project-1-dog-breed-identification/sample_submission.csv')
test_img = submission['id']
x_test_feature = []
i = 0 # initialization
for f in tqdm(test_img.values): # ID in `sample_submission.csv` should help you loop through `test` folder
    img = cv2.imread('/kaggle/input/dpl-project-1-dog-breed-identification/test/{}.jpg'.format(f), 0)
    img_resize = cv2.resize(img, (img_rows, img_cols)) 
    x_test_feature.append(img_resize)
x_test_data = np.array(x_test_feature, np.float32) / 255. 
x_test_data = np.expand_dims(x_test_data, axis = 3)
```

## Model

```python
model = Sequential()
model.add(Convolution2D(6, (5, 5), activation='tanh', strides=(1, 1), input_shape=(32, 32, 1)))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))
model.add(Convolution2D(16, (5, 5), activation='tanh', strides=(1, 1)))
model.add(MaxPooling2D((2, 2), strides=(2, 2)))
model.add(Flatten())
model.add(Dense(120, activation='tanh'))
model.add(Dense(120, activation='softmax'))
batch_size = 128 
nb_epochs = 10
model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(),
              metrics=['accuracy'])
history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=nb_epochs,
                    verbose=1, 
                    validation_data=(x_val, y_val),
                    initial_epoch=0)
```

## Submit
```python
results = model.predict(x_test_data)
prediction = pd.DataFrame(results)
prediction.columns = one_hot.columns.values # Set column names to those generated by the one-hot encoding earlier
prediction.insert(0, 'id', submission['id']) # Insert the column id from the sample_submission at the start of the data frame
submission = prediction
submission.to_csv('submission.csv', index=False)
```
